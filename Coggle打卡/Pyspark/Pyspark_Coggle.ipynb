{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 任务1：PySpark数据处理\n",
    "* 步骤1：使用Python链接Spark环境\n",
    "* 步骤2：创建dateframe数据\n",
    "* 步骤3：用spark执行以下逻辑：找到数据行数、列数\n",
    "* 步骤4：用spark筛选class为1的样本\n",
    "* 步骤5：用spark筛选language >90 或 math> 90的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('pyspark_test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   002|    2|      87|  81|     90|    83|      83|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "|   004|    2|      65|  87|     94|    73|      88|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   006|    3|      84|  82|     85|    73|      99|\n",
      "|   007|    3|      56|  76|     63|    72|      87|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "|   009|    2|      63|  72|     87|    98|      64|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = spark.createDataFrame([('001','1',100,87,67,83,98), ('002','2',87,81,90,83,83), ('003','3',86,91,83,89,63),\n",
    "                            ('004','2',65,87,94,73,88), ('005','1',76,62,89,81,98), ('006','3',84,82,85,73,99),\n",
    "                            ('007','3',56,76,63,72,87), ('008','1',55,62,46,78,71), ('009','2',63,72,87,98,64)],                           ['number','class','language','math','english','physic','chemical'])\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(test.count())\n",
    "print(len(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.filter(test['class']==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.where('class==1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.where('language>90 or math >90').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 任务2：PySpark数据统计\n",
    "\n",
    "* 步骤1：读取文件https://cdn.coggle.club/Pokemon.csv\n",
    "* 步骤2：将读取的进行保存，表头也需要保存\n",
    "* 步骤3：分析每列的类型，取值个数\n",
    "* 步骤4：分析每列是否包含缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|                Name|Type 1|Type 2|Total| HP|Attack|Defense|Sp Atk|Sp Def|Speed|Generation|Legendary|\n",
      "+--------------------+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "|           Bulbasaur| Grass|Poison|  318| 45|    49|     49|    65|    65|   45|         1|    false|\n",
      "|             Ivysaur| Grass|Poison|  405| 60|    62|     63|    80|    80|   60|         1|    false|\n",
      "|            Venusaur| Grass|Poison|  525| 80|    82|     83|   100|   100|   80|         1|    false|\n",
      "|VenusaurMega Venu...| Grass|Poison|  625| 80|   100|    123|   122|   120|   80|         1|    false|\n",
      "|          Charmander|  Fire|  null|  309| 39|    52|     43|    60|    50|   65|         1|    false|\n",
      "+--------------------+------+------+-----+---+------+-------+------+------+-----+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "spark.sparkContext.addFile(\"https://cdn.coggle.club/Pokemon.csv\")\n",
    "df = spark.read.csv(\"file://\"+SparkFiles.get(\"Pokemon.csv\"), header=True, inferSchema= True)\n",
    "df = df.withColumnRenamed('Sp. Atk', 'Sp Atk')\n",
    "df = df.withColumnRenamed('Sp. Def', 'Sp Def')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为csv文件\n",
    "df.write.options(header='True', delimiter=',')\\\n",
    "    .mode('overwrite').csv('.\\Pokemon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'),\n",
       " ('Type 1', 'string'),\n",
       " ('Type 2', 'string'),\n",
       " ('Total', 'int'),\n",
       " ('HP', 'int'),\n",
       " ('Attack', 'int'),\n",
       " ('Defense', 'int'),\n",
       " ('Sp Atk', 'int'),\n",
       " ('Sp Def', 'int'),\n",
       " ('Speed', 'int'),\n",
       " ('Generation', 'int'),\n",
       " ('Legendary', 'boolean')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Name        800 non-null    object\n",
      " 1   Type 1      800 non-null    object\n",
      " 2   Type 2      414 non-null    object\n",
      " 3   Total       800 non-null    int32 \n",
      " 4   HP          800 non-null    int32 \n",
      " 5   Attack      800 non-null    int32 \n",
      " 6   Defense     800 non-null    int32 \n",
      " 7   Sp Atk      800 non-null    int32 \n",
      " 8   Sp Def      800 non-null    int32 \n",
      " 9   Speed       800 non-null    int32 \n",
      " 10  Generation  800 non-null    int32 \n",
      " 11  Legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int32(8), object(3)\n",
      "memory usage: 44.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.toPandas().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name          False\n",
       "Type 1        False\n",
       "Type 2         True\n",
       "Total         False\n",
       "HP            False\n",
       "Attack        False\n",
       "Defense       False\n",
       "Sp Atk        False\n",
       "Sp Def        False\n",
       "Speed         False\n",
       "Generation    False\n",
       "Legendary     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 任务3：PySpark分组聚合\n",
    "\n",
    "* 步骤1：读取文件https://cdn.coggle.club/Pokemon.csv\n",
    "* 步骤2：学习groupby分组聚合的使用\n",
    "* 步骤3：学习agg分组聚合的使用\n",
    "* 步骤4：学习transform的使用\n",
    "* 步骤5：使用groupby、agg、transform，统计数据在Type 1分组下 HP的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+-----+---+------+-------+-------+-------+-----+----------+---------+\n",
      "|     Name|Type 1|Type 2|Total| HP|Attack|Defense|Sp. Atk|Sp. Def|Speed|Generation|Legendary|\n",
      "+---------+------+------+-----+---+------+-------+-------+-------+-----+----------+---------+\n",
      "|Bulbasaur| Grass|Poison|  318| 45|    49|     49|     65|     65|   45|         1|    false|\n",
      "+---------+------+------+-----+---+------+-------+-------+-------+-----+----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "spark.sparkContext.addFile(\"https://cdn.coggle.club/Pokemon.csv\")\n",
    "df = spark.read.csv(\"file://\"+SparkFiles.get(\"Pokemon.csv\"), header=True, inferSchema= True)\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|  Type 1|          avg(HP)|\n",
      "+--------+-----------------+\n",
      "|   Water|          72.0625|\n",
      "|  Poison|            67.25|\n",
      "|   Steel|65.22222222222223|\n",
      "|    Rock|65.36363636363636|\n",
      "|     Ice|             72.0|\n",
      "|   Ghost|          64.4375|\n",
      "|   Fairy|74.11764705882354|\n",
      "| Psychic|70.63157894736842|\n",
      "|  Dragon|          83.3125|\n",
      "|  Flying|            70.75|\n",
      "|     Bug|56.88405797101449|\n",
      "|Electric|59.79545454545455|\n",
      "|    Fire|69.90384615384616|\n",
      "|  Ground|         73.78125|\n",
      "|    Dark|66.80645161290323|\n",
      "|Fighting|69.85185185185185|\n",
      "|   Grass|67.27142857142857|\n",
      "|  Normal|77.27551020408163|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Type 1').agg({\"HP\":'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      67.271429\n",
       "1      67.271429\n",
       "2      67.271429\n",
       "3      67.271429\n",
       "4      69.903846\n",
       "         ...    \n",
       "795    65.363636\n",
       "796    65.363636\n",
       "797    70.631579\n",
       "798    70.631579\n",
       "799    69.903846\n",
       "Name: HP, Length: 800, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().groupby('Type 1')['HP'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 任务4：SparkSQL基础语法\n",
    "\n",
    "* 步骤1：使用Spark SQL完成任务1里面的数据筛选\n",
    "* 步骤2：使用Spark SQL完成任务2里面的统计（列可以不统计）\n",
    "* 步骤3：使用Spark SQL完成任务3的分组统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   005|    1|      76|  62|     89|    81|      98|\n",
      "|   008|    1|      55|  62|     46|    78|      71|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|number|class|language|math|english|physic|chemical|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "|   001|    1|     100|  87|     67|    83|      98|\n",
      "|   003|    3|      86|  91|     83|    89|      63|\n",
      "+------+-----+--------+----+-------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.createOrReplaceTempView(\"test\")\n",
    "\n",
    "spark.sql(\"select * from test where class=1\").show()\n",
    "spark.sql(\"select * from test where language>90 or math>90\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|  col_name|data_type|comment|\n",
      "+----------+---------+-------+\n",
      "|      Name|   string|   null|\n",
      "|    Type 1|   string|   null|\n",
      "|    Type 2|   string|   null|\n",
      "|     Total|      int|   null|\n",
      "|        HP|      int|   null|\n",
      "|    Attack|      int|   null|\n",
      "|   Defense|      int|   null|\n",
      "|   Sp. Atk|      int|   null|\n",
      "|   Sp. Def|      int|   null|\n",
      "|     Speed|      int|   null|\n",
      "|Generation|      int|   null|\n",
      "| Legendary|  boolean|   null|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "spark.sql(\"DESCRIBE df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|  Type 1|          avg(HP)|\n",
      "+--------+-----------------+\n",
      "|   Water|          72.0625|\n",
      "|  Poison|            67.25|\n",
      "|   Steel|65.22222222222223|\n",
      "|    Rock|65.36363636363636|\n",
      "|     Ice|             72.0|\n",
      "|   Ghost|          64.4375|\n",
      "|   Fairy|74.11764705882354|\n",
      "| Psychic|70.63157894736842|\n",
      "|  Dragon|          83.3125|\n",
      "|  Flying|            70.75|\n",
      "|     Bug|56.88405797101449|\n",
      "|Electric|59.79545454545455|\n",
      "|    Fire|69.90384615384616|\n",
      "|  Ground|         73.78125|\n",
      "|    Dark|66.80645161290323|\n",
      "|Fighting|69.85185185185185|\n",
      "|   Grass|67.27142857142857|\n",
      "|  Normal|77.27551020408163|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"df_1\")\n",
    "\n",
    "spark.sql(\"select `Type 1`, avg(HP) from df_1 group by `Type 1`\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 任务5：SparkML基础：数据编码\n",
    "\n",
    "* 步骤1：学习Spark ML中数据编码模块\n",
    ">* https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#feature\n",
    ">* https://spark.apache.org/docs/latest/ml-features.html\n",
    "* 步骤2：读取文件Pokemon.csv，理解数据字段含义\n",
    "* 步骤3：将其中的类别属性使用onehotencoder\n",
    "* 步骤4：对其中的数值属性字段使用minmaxscaler\n",
    "* 步骤5：对编码后的属性使用pca进行降维（维度可以自己选择）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
